import type { ModelInfo } from "../model.js"

/**
 * Azure OpenAI model metadata.
 *
 * NOTE:
 * - Azure OpenAI uses *deployment names* at runtime, but Roo still needs underlying model
 *   capabilities (maxTokens/contextWindow/etc.) for validation and parameter shaping.
 * - This list contains OpenAI models deployable through Azure OpenAI (.openai.azure.com).
 *   Non-OpenAI models (e.g. DeepSeek, Llama, Claude) require the Azure AI Model Inference
 *   API (services.ai.azure.com/models) which is a different endpoint and API surface.
 */
export const azureModels = {
	"codex-mini": {
		maxTokens: 100_000,
		contextWindow: 200_000,
		supportsImages: false,
		supportsPromptCache: true,
		inputPrice: 1.5,
		outputPrice: 6,
		cacheReadsPrice: 0.375,
		supportsTemperature: false,
		description: "Codex Mini",
	},
	"gpt-4-turbo": {
		maxTokens: 4_096,
		contextWindow: 128_000,
		supportsImages: true,
		supportsPromptCache: false,
		inputPrice: 10,
		outputPrice: 30,
		supportsTemperature: true,
		description: "GPT-4 Turbo",
	},
	"gpt-4-turbo-vision": {
		maxTokens: 4_096,
		contextWindow: 128_000,
		supportsImages: true,
		supportsPromptCache: false,
		inputPrice: 10,
		outputPrice: 30,
		supportsTemperature: true,
		description: "GPT-4 Turbo Vision",
	},
	"gpt-4.1": {
		maxTokens: 32_768,
		contextWindow: 1_047_576,
		supportsImages: true,
		supportsPromptCache: true,
		inputPrice: 2,
		outputPrice: 8,
		cacheReadsPrice: 0.5,
		supportsTemperature: true,
		description: "GPT-4.1",
	},
	"gpt-4.1-mini": {
		maxTokens: 32_768,
		contextWindow: 1_047_576,
		supportsImages: true,
		supportsPromptCache: true,
		inputPrice: 0.4,
		outputPrice: 1.6,
		cacheReadsPrice: 0.1,
		supportsTemperature: true,
		description: "GPT-4.1 mini",
	},
	"gpt-4.1-nano": {
		maxTokens: 32_768,
		contextWindow: 1_047_576,
		supportsImages: true,
		supportsPromptCache: true,
		inputPrice: 0.1,
		outputPrice: 0.4,
		cacheReadsPrice: 0.03,
		supportsTemperature: true,
		description: "GPT-4.1 nano",
	},
	"gpt-4o": {
		maxTokens: 16_384,
		contextWindow: 128_000,
		supportsImages: true,
		supportsPromptCache: true,
		inputPrice: 2.5,
		outputPrice: 10,
		cacheReadsPrice: 1.25,
		supportsTemperature: true,
		description: "GPT-4o",
	},
	"gpt-4o-mini": {
		maxTokens: 16_384,
		contextWindow: 128_000,
		supportsImages: true,
		supportsPromptCache: true,
		inputPrice: 0.15,
		outputPrice: 0.6,
		cacheReadsPrice: 0.08,
		supportsTemperature: true,
		description: "GPT-4o mini",
	},
	"gpt-5": {
		maxTokens: 128_000,
		contextWindow: 272_000,
		includedTools: ["apply_patch"],
		excludedTools: ["apply_diff", "write_to_file"],
		supportsImages: true,
		supportsPromptCache: true,
		supportsReasoningEffort: ["minimal", "low", "medium", "high"],
		reasoningEffort: "medium",
		inputPrice: 1.25,
		outputPrice: 10,
		cacheReadsPrice: 0.13,
		supportsVerbosity: true,
		supportsTemperature: false,
		description: "GPT-5",
	},
	"gpt-5-codex": {
		maxTokens: 128_000,
		contextWindow: 400_000,
		includedTools: ["apply_patch"],
		excludedTools: ["apply_diff", "write_to_file"],
		supportsImages: true,
		supportsPromptCache: true,
		supportsReasoningEffort: ["low", "medium", "high"],
		reasoningEffort: "medium",
		inputPrice: 1.25,
		outputPrice: 10,
		cacheReadsPrice: 0.13,
		supportsTemperature: false,
		description: "GPT-5-Codex",
	},
	"gpt-5-mini": {
		maxTokens: 128_000,
		contextWindow: 272_000,
		includedTools: ["apply_patch"],
		excludedTools: ["apply_diff", "write_to_file"],
		supportsImages: true,
		supportsPromptCache: true,
		supportsReasoningEffort: ["minimal", "low", "medium", "high"],
		reasoningEffort: "medium",
		inputPrice: 0.25,
		outputPrice: 2,
		cacheReadsPrice: 0.03,
		supportsVerbosity: true,
		supportsTemperature: false,
		description: "GPT-5 Mini",
	},
	"gpt-5-nano": {
		maxTokens: 128_000,
		contextWindow: 272_000,
		includedTools: ["apply_patch"],
		excludedTools: ["apply_diff", "write_to_file"],
		supportsImages: true,
		supportsPromptCache: true,
		supportsReasoningEffort: ["minimal", "low", "medium", "high"],
		reasoningEffort: "medium",
		inputPrice: 0.05,
		outputPrice: 0.4,
		cacheReadsPrice: 0.01,
		supportsVerbosity: true,
		supportsTemperature: false,
		description: "GPT-5 Nano",
	},
	"gpt-5-pro": {
		maxTokens: 272_000,
		contextWindow: 400_000,
		includedTools: ["apply_patch"],
		excludedTools: ["apply_diff", "write_to_file"],
		supportsImages: true,
		supportsPromptCache: false,
		supportsReasoningEffort: ["minimal", "low", "medium", "high"],
		reasoningEffort: "medium",
		inputPrice: 15,
		outputPrice: 120,
		supportsVerbosity: true,
		supportsTemperature: false,
		description: "GPT-5 Pro",
	},
	"gpt-5.1": {
		maxTokens: 128_000,
		contextWindow: 272_000,
		includedTools: ["apply_patch"],
		excludedTools: ["apply_diff", "write_to_file"],
		supportsImages: true,
		supportsPromptCache: true,
		promptCacheRetention: "24h",
		supportsReasoningEffort: ["none", "low", "medium", "high"],
		reasoningEffort: "medium",
		inputPrice: 1.25,
		outputPrice: 10,
		cacheReadsPrice: 0.125,
		supportsVerbosity: true,
		supportsTemperature: false,
		description: "GPT-5.1",
	},
	"gpt-5.1-chat": {
		maxTokens: 16_384,
		contextWindow: 128_000,
		includedTools: ["apply_patch"],
		excludedTools: ["apply_diff", "write_to_file"],
		supportsImages: true,
		supportsPromptCache: true,
		promptCacheRetention: "24h",
		inputPrice: 1.25,
		outputPrice: 10,
		cacheReadsPrice: 0.125,
		supportsTemperature: false,
		description: "GPT-5.1 Chat",
	},
	"gpt-5.1-codex": {
		maxTokens: 128_000,
		contextWindow: 400_000,
		includedTools: ["apply_patch"],
		excludedTools: ["apply_diff", "write_to_file"],
		supportsImages: true,
		supportsPromptCache: true,
		promptCacheRetention: "24h",
		supportsReasoningEffort: ["low", "medium", "high"],
		reasoningEffort: "medium",
		inputPrice: 1.25,
		outputPrice: 10,
		cacheReadsPrice: 0.125,
		supportsTemperature: false,
		description: "GPT-5.1 Codex",
	},
	"gpt-5.1-codex-max": {
		maxTokens: 128_000,
		contextWindow: 400_000,
		includedTools: ["apply_patch"],
		excludedTools: ["apply_diff", "write_to_file"],
		supportsImages: true,
		supportsPromptCache: true,
		promptCacheRetention: "24h",
		supportsReasoningEffort: ["low", "medium", "high", "xhigh"],
		reasoningEffort: "medium",
		inputPrice: 1.25,
		outputPrice: 10,
		cacheReadsPrice: 0.125,
		supportsTemperature: false,
		description: "GPT-5.1 Codex Max",
	},
	"gpt-5.1-codex-mini": {
		maxTokens: 128_000,
		contextWindow: 400_000,
		includedTools: ["apply_patch"],
		excludedTools: ["apply_diff", "write_to_file"],
		supportsImages: true,
		supportsPromptCache: true,
		promptCacheRetention: "24h",
		supportsReasoningEffort: ["low", "medium", "high"],
		reasoningEffort: "medium",
		inputPrice: 0.25,
		outputPrice: 2,
		cacheReadsPrice: 0.025,
		supportsTemperature: false,
		description: "GPT-5.1 Codex Mini",
	},
	"gpt-5.2": {
		maxTokens: 128_000,
		contextWindow: 400_000,
		includedTools: ["apply_patch"],
		excludedTools: ["apply_diff", "write_to_file"],
		supportsImages: true,
		supportsPromptCache: true,
		promptCacheRetention: "24h",
		supportsReasoningEffort: ["none", "low", "medium", "high", "xhigh"],
		reasoningEffort: "medium",
		inputPrice: 1.75,
		outputPrice: 14,
		cacheReadsPrice: 0.125,
		supportsVerbosity: true,
		supportsTemperature: false,
		description: "GPT-5.2",
	},
	"gpt-5.2-chat": {
		maxTokens: 16_384,
		contextWindow: 128_000,
		includedTools: ["apply_patch"],
		excludedTools: ["apply_diff", "write_to_file"],
		supportsImages: true,
		supportsPromptCache: true,
		inputPrice: 1.75,
		outputPrice: 14,
		cacheReadsPrice: 0.175,
		supportsTemperature: false,
		description: "GPT-5.2 Chat",
	},
	"gpt-5.2-codex": {
		maxTokens: 128_000,
		contextWindow: 400_000,
		includedTools: ["apply_patch"],
		excludedTools: ["apply_diff", "write_to_file"],
		supportsImages: true,
		supportsPromptCache: true,
		promptCacheRetention: "24h",
		supportsReasoningEffort: ["low", "medium", "high", "xhigh"],
		reasoningEffort: "medium",
		inputPrice: 1.75,
		outputPrice: 14,
		cacheReadsPrice: 0.175,
		supportsTemperature: false,
		description: "GPT-5.2 Codex",
	},
	o1: {
		maxTokens: 100_000,
		contextWindow: 200_000,
		supportsImages: true,
		supportsPromptCache: true,
		inputPrice: 15,
		outputPrice: 60,
		cacheReadsPrice: 7.5,
		supportsTemperature: false,
		description: "o1",
	},
	"o1-mini": {
		maxTokens: 65_536,
		contextWindow: 128_000,
		supportsImages: false,
		supportsPromptCache: true,
		inputPrice: 1.1,
		outputPrice: 4.4,
		cacheReadsPrice: 0.55,
		supportsTemperature: false,
		description: "o1-mini",
	},
	"o1-preview": {
		maxTokens: 32_768,
		contextWindow: 128_000,
		supportsImages: false,
		supportsPromptCache: true,
		inputPrice: 16.5,
		outputPrice: 66,
		cacheReadsPrice: 8.25,
		supportsTemperature: false,
		description: "o1-preview",
	},
	o3: {
		maxTokens: 100_000,
		contextWindow: 200_000,
		supportsImages: true,
		supportsPromptCache: true,
		supportsReasoningEffort: ["low", "medium", "high"],
		reasoningEffort: "medium",
		inputPrice: 2,
		outputPrice: 8,
		cacheReadsPrice: 0.5,
		supportsTemperature: false,
		description: "o3",
	},
	"o3-mini": {
		maxTokens: 100_000,
		contextWindow: 200_000,
		supportsImages: false,
		supportsPromptCache: true,
		supportsReasoningEffort: ["low", "medium", "high"],
		reasoningEffort: "medium",
		inputPrice: 1.1,
		outputPrice: 4.4,
		cacheReadsPrice: 0.55,
		supportsTemperature: false,
		description: "o3-mini",
	},
	"o4-mini": {
		maxTokens: 100_000,
		contextWindow: 200_000,
		supportsImages: true,
		supportsPromptCache: true,
		supportsReasoningEffort: ["low", "medium", "high"],
		reasoningEffort: "medium",
		inputPrice: 1.1,
		outputPrice: 4.4,
		cacheReadsPrice: 0.28,
		supportsTemperature: false,
		description: "o4-mini",
	},
} as const satisfies Record<string, ModelInfo>

export type AzureModelId = keyof typeof azureModels

export const azureDefaultModelId: AzureModelId = "gpt-4o"

export const azureDefaultModelInfo: ModelInfo = azureModels[azureDefaultModelId]
